# Задача регрессии

Имеется датасет с объявлениями о продаже квартир в городе Новосибирске. 

В таблице всего 15000 строк, соответствующих разным квартирам, и 37 столбцов с признаками.

Предсказывается удельная стоимость квартиры (руб/кв.м).

Метрика ошибки - MdAPE - медиана модуля ошибки в процентах.

Произведена нормализация, отброшены выбросы, обучающая и тестовая выборки разделены в пропорции 3/1.

Для оценки использовалась линейная регрессия (чтобы разобраться с интерфейсом ноутбука), К-ближайшие соседи и дерево принятия решений.

После удаления выбросов: 13836 строк.

Пропущенные значения: В функциональных зонах около трети, было предпринято заполнение случайными величинами и выделение в отдельный признак.
При выделении в отдельный признак ошибка оценки стала меньше. 

Ценовая зона - несбалансированный класс, но можно объединить зоны меньше 15% в общий признак, тогда признак станет сбалансированным.

Категориальные признаки: Тип рынка и Функциональная зона.


![image](https://github.com/user-attachments/assets/549d783c-0013-46a9-9816-4908dbb4350d)
![image](https://github.com/user-attachments/assets/0644ce5d-633f-4330-afcc-56cf50468a6b)



# Результат работы модели:

MdAPE для линейной регрессии: 15.28%

MdAPE для Лассо регрессии: 15.29%

MdAPE для Ридж регрессии: 15.29%

Среднеквадратическое отклонение: 867427656.23

R-квадрат: 0.30

# K-NN:

![image](https://github.com/user-attachments/assets/7cf8e96d-f3dc-4e7b-a9bd-6dcaacbce5af)


Среднеквадратическое отклонение: 508400682.25

R-квадрат: 0.59

MdAPE на обучающих данных: 7.53%

MdAPE на тестовых данных: 8.77%

# Дерево решений:


![image](https://github.com/user-attachments/assets/6b50cefc-1725-41be-b35e-3e9a6af4ee6e)


Среднеквадратическое отклонение: 442229835.49

R-квадрат: 0.64

MdAPE на обучающих данных: 7.01%

MdAPE для дерева принятия решений: 8.20%

Лучший результат показало дерево решений, ошибка 8.2%
Худший результат - K-NN, ошибка 8.77%


# Кластеризация 

1. Метод KMeans

![image](https://github.com/user-attachments/assets/a7d654b5-f441-4183-8157-e42586615c9b)

KMeans ARI: 0.022991190213712633

KMeans NMI: 0.04598343595400444

2. Метод DBSCAN

![image](https://github.com/user-attachments/assets/be344c9e-7fc3-4884-9277-d60b8dbf040a)

DBSCAN ARI: -0.00024188476296317958

DBSCAN NMI: 0.03947657367397556

3. Иерархическая кластеризация

![image](https://github.com/user-attachments/assets/3d28d3b0-cb90-42ca-8866-8c9436931e93)

Agglomerative ARI: 0.04599076416534933

Agglomerative NMI: 0.046766914951804406

Истинные метки:

![image](https://github.com/user-attachments/assets/32972a10-217e-4083-8c28-5c443e1e0bf6)


Лучший метод кластеризации - Иерархическая кластеризация, DBSCAN плохо справляется из-за разной плотности в структуре данных, KMeans выдаёт почти такой же результат, что и иерархическая кластеризация, но для него линия разделения кластеров на графике чуть правее, когда на графике истинных меток видно, что слева более сконцентрированы квартиры со вторичного рынка, а справа первичного. Учитывая, что методы работают без учителя, результат неплохой, метрики, сравнивающие качество кластеризации показывают, что полученный результат на самую малость, но лучше, чем случайная кластеризация.

Процент правильно кластеризованных меток для KMeans: 58.17%

Процент правильно кластеризованных меток для DBSCAN: 56.62%

Процент правильно кластеризованных меток для Agglomerative: 60.81% 
